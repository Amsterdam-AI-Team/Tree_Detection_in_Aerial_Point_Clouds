{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "228c23f8-c981-4664-a8dd-8f02cf40abbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract tree trunks\n",
    "\n",
    "The input for this notebook is the pre-processed cloud that results from notebook `1. Tree filter.ipynb`. From this data we try to extract individual tree trunks. The methods used here are based on the [internship project of Jorges Nofulla](https://github.com/Amsterdam-Internships/Tree-trunk-segmentation).\n",
    "\n",
    "(**Note**: this notebook currently works on a single input file only, in contrast to notebooks 1-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2c6a1-d483-44c8-a489-bad108e282a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import laspy as lp\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial import KDTree\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapefile\n",
    "import pathlib\n",
    "\n",
    "import gvl.trunk_utils as utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a97d2cf8-6b5a-4c27-bb0e-2230a2532db7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a28c8-4f82-44bb-8f88-a8f0dbe99d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = pathlib.Path('../data') \n",
    "\n",
    "my_tile = '2496_9727'\n",
    "\n",
    "# Input\n",
    "input_las = DATA_FOLDER / (\"ahn4_trees/trees_\" + my_tile + \".laz\")\n",
    "area_file = DATA_FOLDER / \"ground_truth/gt_area.gpkg\"\n",
    "\n",
    "# Output\n",
    "output_dir = DATA_FOLDER / \"ahn4_trunks\"\n",
    "output_trunks = output_dir / (\"trunks_\" + my_tile + \".laz\")\n",
    "output_centroids = output_dir / (\"trunk_centroids_\" + my_tile + \".laz\")\n",
    "\n",
    "CRS = \"epsg:28992\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac988825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (in meters)\n",
    "r = 3  # radius of the search sphere for the initial clustering\n",
    "radius = 0.8  # the radius on which we count the point density in x and y for each point\n",
    "# (the parameter used for local maxima calculation)\n",
    "window_size = 4  # the size of the search window for local maxima in each cluster\n",
    "max_distance = 0.8  # the delineated trunks radius\n",
    "restrict_d = (\n",
    "    3  # the minimum eucledian distance that 2 peaks of the same cluster can have\n",
    ")\n",
    "small_clusters = 100  # the size of the small custers we suspect as outliers\n",
    "# (won't be deleted, they will just merge with a nearby big cluster if there is any,\n",
    "# else they will be taken as individual clusters)\n",
    "small_outliers = 30  # the minimal cluster size to be allowed as a tree.\n",
    "# Deleting every cluster below this value (optional).\n",
    "diff_height = (\n",
    "    1.5  # the difference in height between 2 clusters very close to each other\n",
    ")\n",
    "# (this is the parameter to take care of branches that are classified as a separate cluster)\n",
    "branch_dist = 0.8  # the max distance a branch cluster can be from the main tree\n",
    "min_dist_tree = (\n",
    "    1  # the max distance of 2 clusters to be checked if they are the same tree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38e832f2-80ba-4e9f-9f26-8323959b0c5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load and Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file = lp.read(input_las)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only 'tree' points\n",
    "las_file.points = las_file.points[las_file.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445b5ed-46da-4d6e-91e6-dc1c5b4d94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the file coordinates\n",
    "coord = np.c_[las_file.x, las_file.y, las_file.z]\n",
    "coord.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06b6e389",
   "metadata": {},
   "source": [
    "### Reduce amount of points by downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(coord)\n",
    "pcd_down = pcd.voxel_down_sample(voxel_size=0.5)\n",
    "coord = np.asarray(pcd_down.points)\n",
    "coord.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fb82afb",
   "metadata": {},
   "source": [
    "### Reduce amount of points by selecting an area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb72c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get area data\n",
    "df_area = gpd.read_file(area_file)\n",
    "\n",
    "# Put points in geodataframe\n",
    "df_coord = pd.DataFrame(coord)\n",
    "gdf_coord = gpd.GeoDataFrame(\n",
    "    df_coord, geometry=gpd.points_from_xy(df_coord[0], df_coord[1]), crs=CRS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e96c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only points within area\n",
    "gdf_coord_sel = gdf_coord.sjoin(df_area, predicate=\"within\").drop(\n",
    "    [\"index_right\"], axis=1\n",
    ")\n",
    "coord = np.c_[gdf_coord_sel.geometry.x, gdf_coord_sel.geometry.y, gdf_coord_sel[2]]\n",
    "coord.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "455432c6",
   "metadata": {},
   "source": [
    "### Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc620cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the coordinates by z value\n",
    "position = coord[coord[:, 2].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0210c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of \"point\" class for each set of coordinates\n",
    "points = []\n",
    "for i in range(len(position)):\n",
    "    i = utils.Point(i, position[i])\n",
    "    points.append(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2d8bebd-7aec-42d2-942f-2a09f0226260",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Find centroids of point clusters and tree peaks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05081a96-5242-49ab-985e-7c3085919ea4",
   "metadata": {},
   "source": [
    "1. A collection of points in 3D space is given, with a manually input radius value.\n",
    "2. The code finds groups of points that are within the radius of each other, and it computes their group centroids.\n",
    "3. For each group, it finds the point with the highest Z-value (i.e., the top of the tree), and links it to the centroid.\n",
    "4. The code outputs the index of the closest point to the centroid for each group, and whether each point is the highest point of its group (i.e., at the top of the tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442fa33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all points within distance r of point(s) x\n",
    "tree = scipy.spatial.cKDTree(position)\n",
    "nn = tree.query_ball_point(position, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c083f-9851-45fa-8dfc-bb22c6a091db",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = np.zeros(len(position), dtype=int)\n",
    "centroids = np.zeros((len(position), 3))\n",
    "has_parent = np.zeros(len(position), dtype=bool)\n",
    "\n",
    "# Loop over all points\n",
    "for i, this_nn in enumerate(nn):\n",
    "    # If the point has no neighbors within radius r, it is a tree peak\n",
    "    if len(this_nn) == 1:\n",
    "        links[i] = i\n",
    "        centroids[i] = position[i]\n",
    "        has_parent[i] = True\n",
    "    # If the point has at least one neighbor within radius r\n",
    "    else:\n",
    "        # Find all neighbors with a higher z value\n",
    "        upper_nnbs = [j for j in this_nn if position[j, 2] > position[i, 2]]\n",
    "        # If there are no such neighbors, the point is a tree peak\n",
    "        if not upper_nnbs:\n",
    "            links[i] = i\n",
    "            centroids[i] = position[i]\n",
    "            has_parent[i] = True\n",
    "        # If there are any neighbors with a higher z value\n",
    "        else:\n",
    "            # Calculate the centroid of the group of neighbors\n",
    "            centroids[i] = np.mean(position[upper_nnbs], axis=0)\n",
    "            # Calculate the distances between each neighbor and the centroid\n",
    "            dist = scipy.spatial.distance.cdist(\n",
    "                position[upper_nnbs], [centroids[i]], metric=\"euclidean\"\n",
    "            )\n",
    "            # Find the neighbor closest to the centroid and store its index as a link\n",
    "            links[i] = upper_nnbs[np.argmin(dist)]\n",
    "\n",
    "has_parent = has_parent.astype(\"int\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0641304f-6874-475f-9a89-309fe9847293",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Label the points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45b6cec2-e0af-4e16-92b7-5258bef2040a",
   "metadata": {},
   "source": [
    "1. For each point, the code checks if it has already been assigned to a path.\n",
    "2. If not, it creates a new path and adds the current point to it.\n",
    "3. It then follows the links created in Part 2 to add more points to the path, until it reaches a point with no parent (i.e., at the top of the tree), at which point it ends the path.\n",
    "4. If the code encounters a point that is already in a path, it creates a new network that includes both the new path and the existing path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b019e2-7870-46e9-92c0-608b29d7c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = []\n",
    "all_paths = []\n",
    "for p in points:\n",
    "    current_idx = p.index\n",
    "\n",
    "    if len(points[current_idx].paths) == 0:\n",
    "        end = False\n",
    "\n",
    "        # initialize new path\n",
    "        new_path = utils.Path(len(all_paths))  # len paths as index\n",
    "        all_paths.append(new_path)\n",
    "\n",
    "        # add first point to the path\n",
    "        new_path.add_point(points[current_idx])\n",
    "        points[current_idx].add_path(new_path)\n",
    "\n",
    "        # append path\n",
    "        while end is False:\n",
    "            # point has a parent\n",
    "            if has_parent[current_idx] != 1:\n",
    "                # make link\n",
    "                points[current_idx].linked_to = points[links[current_idx]]\n",
    "\n",
    "                if len(points[current_idx].linked_to.paths) == 0:\n",
    "                    # not in path\n",
    "                    points[current_idx].linked_to.add_path(new_path)\n",
    "                    new_path.add_point(points[current_idx].linked_to)\n",
    "                    current_idx = links[current_idx]\n",
    "\n",
    "                else:\n",
    "                    # in path\n",
    "                    points[current_idx].linked_to.network.add_path(new_path)\n",
    "                    points[current_idx].add_path(new_path)\n",
    "                    points[current_idx].linked_to.add_path(new_path)\n",
    "                    end = True\n",
    "\n",
    "            # point has no parent\n",
    "            # make network, end path\n",
    "            else:\n",
    "                points[current_idx].linked_to = points[current_idx]\n",
    "                # init new network\n",
    "                new_network = utils.Network(len(networks))  # len networks as index\n",
    "                new_network.add_path(\n",
    "                    new_path\n",
    "                )  # path and points are assigned to network\n",
    "                new_network.top = current_idx\n",
    "                new_network.points = new_path.points  # add points to the network\n",
    "                networks.append(new_network)\n",
    "                points[current_idx].network = new_network\n",
    "                end = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb9f8ca0-ebb0-4291-92a5-79e7b4ef367a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Remove all the outlier clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5168f332-463f-4241-8226-86155803b201",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the labels array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5694fc-fd07-463c-a9dc-e8900a804e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to extract and store all our individual tree labels from\n",
    "labels = np.zeros(len(points))\n",
    "\n",
    "# Extract the label value from class network to our new built array\n",
    "for p in points:\n",
    "    labels[p.index] = p.network.index\n",
    "labels = labels.astype(\"int\")\n",
    "\n",
    "array_test = np.column_stack((position, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3b541-34ab-4a67-b75e-04f4a4756d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each cluster label\n",
    "labels_new = array_test[:, 3]\n",
    "array = array_test[:, 0:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "362b248c",
   "metadata": {},
   "source": [
    "### Remove clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23e757-95ae-4e02-aeb5-9f2854d512c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the count of each label\n",
    "unique, counts = np.unique(labels_new, return_counts=True)\n",
    "label_count = dict(zip(unique, counts))\n",
    "\n",
    "# Initialize an empty list to store the indices of the large clusters\n",
    "large_cluster_indices = []\n",
    "\n",
    "# Iterate through the cluster labels\n",
    "for i, label in enumerate(labels_new):\n",
    "    # If the label corresponds to a large cluster, add the index to the list\n",
    "    if label_count.get(label, 0) >= 10:\n",
    "        large_cluster_indices.append(i)\n",
    "\n",
    "# Use the indices of the large clusters to create a new array\n",
    "array_test = array[large_cluster_indices, :]\n",
    "\n",
    "# Add the labels as the last column of the new array\n",
    "array_test = np.column_stack((array_test, labels_new[large_cluster_indices]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f0dec85-96de-4f2e-98b9-628e124f9424",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Fix the small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114be52-b644-49c1-8e62-856bc85facca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the array for the \"fix small clusters\" code\n",
    "labels_2 = array_test[:, 3].astype(\"int\")\n",
    "labels33, point_count33 = np.unique(labels_2, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153088c-218e-43a3-bbaf-b434857abe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterating_array = []\n",
    "for i in range(len(labels33)):\n",
    "    if point_count33[i] <= small_clusters:\n",
    "        iterating_array.append(labels33[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4656378-ea93-4c26-acfe-4daa1e8a9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroids of all clusters in the dataset\n",
    "all_centroids = []\n",
    "all_labs = []\n",
    "for label in np.unique(array_test[:, 3]):\n",
    "    centroid = array_test[array_test[:, 3] == label, :2].mean(axis=0)\n",
    "    all_centroids.append(centroid)\n",
    "    all_labs.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783db14-9efd-4968-a525-609f97d281f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the pairs of the closest clusters\n",
    "tree1 = KDTree(all_centroids)\n",
    "\n",
    "labels_nn = []\n",
    "for i in range(len(all_labs)):\n",
    "    point_cent = all_centroids[i]\n",
    "    dist, idx = tree1.query(point_cent, k=2)\n",
    "    closest_idx = idx[1] if idx[0] == i else idx[0]\n",
    "    labels_nn.append([all_labs[i], all_labs[closest_idx]])\n",
    "\n",
    "# Filter the list so it contains only the small clusters that we will fix\n",
    "filtered_list = [x for x in labels_nn if int(x[0]) in iterating_array]\n",
    "array_test2 = array_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4084d21-4ada-4426-b71f-0ed50e9c0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in filtered_list:\n",
    "    coord_xy = array_test2[array_test2[:, 3] == i[0]]\n",
    "    coord_xy2 = array_test2[array_test2[:, 3] == i[1]]\n",
    "    wk = distance.cdist(coord_xy[:, :2], coord_xy2[:, :2], \"euclidean\")\n",
    "    z = abs(coord_xy[:, 2:3].min() - coord_xy[:, 2:3].min())\n",
    "    kk = array_test2[:, 2][array_test2[:, 3] == i[1]]\n",
    "    z = abs(coord_xy[:, 2:3].min() - kk.min())\n",
    "    if (\n",
    "        len(array_test2[array_test2 == i[0]]) < (small_clusters / 2)\n",
    "        and wk.min() < min_dist_tree\n",
    "    ):\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    if wk.min() < branch_dist and z > diff_height:\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    if (\n",
    "        len(array_test2[array_test2 == i[0]]) < small_clusters\n",
    "        and wk.min() < min_dist_tree / 2\n",
    "    ):\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    coord_xy = []\n",
    "    coord_xy2 = []\n",
    "    wk = []\n",
    "    ind = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48dd44d0-d676-4b26-ac40-64760713e39d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Delete small clusters (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec470d9-21b0-42e3-9d9e-2cca447c5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each cluster label\n",
    "labels_new = array_test[:, 3]\n",
    "array = array_test[:, 0:3]\n",
    "\n",
    "# Create a dictionary to store the count of each label\n",
    "unique, counts = np.unique(labels_new, return_counts=True)\n",
    "label_count = dict(zip(unique, counts))\n",
    "\n",
    "# Initialize an empty list to store the indices of the large clusters\n",
    "large_cluster_indices = []\n",
    "\n",
    "# Iterate through the cluster labels\n",
    "for i, label in enumerate(labels_new):\n",
    "    # If the label corresponds to a large cluster, add the index to the list\n",
    "    if label_count.get(label, 0) >= small_outliers:\n",
    "        large_cluster_indices.append(i)\n",
    "\n",
    "# Use the indices of the large clusters to create a new array\n",
    "array_test = array[large_cluster_indices, :]\n",
    "\n",
    "# Add the labels as the last column of the new array\n",
    "array_test = np.column_stack((array_test, labels_new[large_cluster_indices]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b80a909-e3a0-4e57-8ae4-87e6d990798f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Get the number of points in buffer per point (the local maxima column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d54e6-f1b5-4212-8f30-5cfd79d7b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "points = array_test[:, :2]\n",
    "\n",
    "# Create KDTree from points\n",
    "kd_tree = KDTree(points)\n",
    "\n",
    "# Array to store the number of points in the buffer for each point\n",
    "count = np.zeros(len(points), dtype=int)\n",
    "\n",
    "# Loop over each point and find points in the buffer\n",
    "for i, p in enumerate(points):\n",
    "    idx = kd_tree.query_ball_point(p, radius)\n",
    "    count[i] = len(idx) - 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c4d42d2-aeeb-4541-9f28-52c085f99289",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Find the tree trunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a3c8a-3954-45c4-9e07-cf8743d27c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_local_maxima(full_array, window_size, max_distance, restrict_d):\n",
    "    # get the unique label of tree clusters\n",
    "    unique_clusters = np.unique(full_array[:, 3])\n",
    "    current_label = 1\n",
    "    labels = np.zeros(full_array.shape[0], dtype=np.int64)\n",
    "    full_array = np.column_stack((full_array, labels))\n",
    "    iteration = 0\n",
    "    # Iterate through every single tree cluster separately\n",
    "    for cluster_id in unique_clusters:\n",
    "        peaks1 = []\n",
    "        dist_peaks = 100\n",
    "        # Form an array for the cluster of this iteration\n",
    "        kot_arr = full_array[full_array[:, 3] == cluster_id]\n",
    "        x1 = kot_arr[:, 0]\n",
    "        y1 = kot_arr[:, 1]\n",
    "        z1 = kot_arr[:, 2]\n",
    "        p1 = kot_arr[:, 4]\n",
    "        labels_k = kot_arr[:, 5]\n",
    "        # Now we iterate through each point of the cluster of this iteration\n",
    "        for i in range(len(kot_arr)):\n",
    "            # We form a search window around each point of the cluster\n",
    "            x_min = x1[i] - window_size\n",
    "            x_max = x1[i] + window_size\n",
    "            y_min = y1[i] - window_size\n",
    "            y_max = y1[i] + window_size\n",
    "            in_window = np.bitwise_and(x1 >= x_min, x1 <= x_max)\n",
    "            in_window = np.bitwise_and(\n",
    "                in_window, np.bitwise_and(y1 >= y_min, y1 <= y_max)\n",
    "            )\n",
    "            in_window = np.bitwise_and(in_window, kot_arr[:, 3] == cluster_id)\n",
    "\n",
    "            # Calculate and save the distances between the local maximas we find.\n",
    "            if len(peaks1) > 0:\n",
    "                this_point = [x1[i], y1[i]]\n",
    "                peak_array = np.array(peaks1)\n",
    "                this_point = np.array(this_point)\n",
    "                this_point = this_point.reshape(1, 2)\n",
    "                dist_peaks = distance.cdist(peak_array, this_point, \"euclidean\")\n",
    "\n",
    "            # We find the local maximas for each window\n",
    "            # Then we restric every local maximas that are way too close with each other with\n",
    "            # the parameter \"restrict_d\". Then the local maximas with an accepted distace between\n",
    "            # each other are relabeld as a unique number for each unique tree.\n",
    "            if np.max(p1[in_window]) == p1[i] and np.min(dist_peaks) > restrict_d:\n",
    "                peaks1.append([x1[i], y1[i]])\n",
    "                points_to_label = np.argwhere(\n",
    "                    np.logical_and(\n",
    "                        np.abs(x1 - x1[i]) <= max_distance,\n",
    "                        np.abs(y1 - y1[i]) <= max_distance,\n",
    "                    )\n",
    "                )\n",
    "                points_to_label = points_to_label.flatten()\n",
    "                if labels_k[i] == 0:\n",
    "                    labels_k[points_to_label] = current_label\n",
    "                    current_label += 1\n",
    "                else:\n",
    "                    labels_k[points_to_label] = labels_k[i]\n",
    "\n",
    "        # we create a new array with the new labels for trunks\n",
    "        new_2 = np.c_[x1, y1, z1, labels_k]\n",
    "        if iteration == 0:\n",
    "            final_result = new_2\n",
    "        else:\n",
    "            final_result = np.vstack((final_result, new_2))\n",
    "        iteration = 1\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a92c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trunks\n",
    "full_array = np.column_stack((array_test, count))\n",
    "Final_labels = cluster_local_maxima(full_array, window_size, max_distance, restrict_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3dfae7-36f4-4e9b-84e9-708f0e08896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of trees in this las file\n",
    "tree_count = np.unique(Final_labels[:, 3])\n",
    "print(\"there are\", len(tree_count), \"trees in this area\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16071fbd",
   "metadata": {},
   "source": [
    "## 8. Store results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0787fdd4-1697-4da9-b735-ac408e086863",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the trunk Point Cloud as a new LAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d3b07-0469-45ef-95bd-d40428c553f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.linspace(0, 1, 100)\n",
    "np.random.shuffle(vals)\n",
    "cmap = plt.cm.colors.ListedColormap(plt.cm.tab20(vals))\n",
    "header = lp.LasHeader()\n",
    "header.data_format_id = 2\n",
    "\n",
    "new_las = lp.LasData(header)\n",
    "new_las.header.scale = [0.01, 0.01, 0.01]\n",
    "new_las.header.offset = [\n",
    "    Final_labels[:, 0].min(),\n",
    "    Final_labels[:, 1].min(),\n",
    "    Final_labels[:, 2].min(),\n",
    "]\n",
    "new_las.x = Final_labels[:, 0]\n",
    "new_las.y = Final_labels[:, 1]\n",
    "new_las.z = Final_labels[:, 2]\n",
    "new_las.pt_src_id = Final_labels[:, 3].astype(\"uint16\")\n",
    "new_las.write(output_trunks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "756d78e9",
   "metadata": {},
   "source": [
    "### Get the centroid in X and Y for each tree trunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd57a99-e402-4007-baab-ec4c1dcc5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique cluster labels excluding label zero\n",
    "Centroid_tree = np.unique(Final_labels[:, 3])[1:]\n",
    "# Initialize an empty list to store the centroids for each cluster\n",
    "centroids_array = []\n",
    "\n",
    "# Iterate through each cluster and find the centroid\n",
    "for label in Centroid_tree:\n",
    "    cluster_points = Final_labels[Final_labels[:, 3] == label][:, :2]\n",
    "    centroid = list(np.mean(cluster_points, axis=0))\n",
    "    centroids_array.append([centroid[0], centroid[1], label])\n",
    "\n",
    "centroids_array = np.array(centroids_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06ec598e-1c28-4a5b-81a6-857e98c4e56f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the tree centroids as 2D points (shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da509d-d268-4c22-9169-ae366b4b6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new shapefile\n",
    "sf = shapefile.Writer(output_centroids, shapeType=shapefile.POINT)\n",
    "\n",
    "# Define the fields for the shapefile\n",
    "sf.field(\"label\", \"N\")\n",
    "\n",
    "# Iterate through each row of the array and add a point to the shapefile\n",
    "for row in centroids_array:\n",
    "    # Extract the x, y, and label values from the row\n",
    "    x, y, label = row\n",
    "\n",
    "    # Add a point to the shapefile with the x and y coordinates\n",
    "    sf.point(x, y)\n",
    "\n",
    "    # Set the attributes for the point\n",
    "    sf.record(label)\n",
    "\n",
    "# Save and close the shapefile\n",
    "sf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95f338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
