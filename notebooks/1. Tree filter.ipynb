{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344c6f6a-6a65-4fd5-901f-ad233350078b",
   "metadata": {},
   "source": [
    "# Pre-processing and Filtering\n",
    "\n",
    "This notebook takes as input a folder with AHN point cloud tiles (assumed to be 1x1 km), and performs a number of pre-processing and filtering steps. The output is a reduced point cloud containing probable trees and other \"unknown\" elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ba0cd-6204-4b97-8739-fa01dd93bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import laspy\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as sg\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from upcp.utils import ahn_utils\n",
    "from upcp.utils.interpolation import FastGridInterpolator\n",
    "from upcp.region_growing.label_connected_comp import LabelConnectedComp\n",
    "\n",
    "import gvl.helper_functions as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f19ce-ca70-4952-9db2-5f8bdf8130fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  # temporary, to supress deprecationwarnings from shapely\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de515d-1ad2-48a9-afd7-7b6e09eb093e",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d5655-b6b9-4e74-bdee-27d8914c9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FOLDER = pathlib.Path('../datasets/AHN4')\n",
    "\n",
    "# Input: AHN subtiles created using notebook \"0. LAS Splitter.ipynb\"\n",
    "input_dir = BASE_FOLDER / 'AMS_subtiles_1000'\n",
    "output_dir = BASE_FOLDER / 'AMS_subtiles_1000_reduced'\n",
    "\n",
    "# DTM corresponding to AHN subtiles, stored as .npz, created using notebook \"0. LAS Splitter.ipynb\"\n",
    "ahn_dtm_folder = BASE_FOLDER / 'npz_subtiles_1000'\n",
    "\n",
    "# This reference file contains known tree locations, if available. \n",
    "# The geopackage contains a 'geometry' column with geopandas POINT coordinates.\n",
    "# tree_ref_file = '../datasets/validation/tree_locations_amsterdam_xy_rijksdriehoek.gpkg'\n",
    "\n",
    "MIN_HAG = 2.5  # Minimum height above ground in meters\n",
    "\n",
    "tree_filter = {'grid_size': 0.5,\n",
    "               'min_component_size': 50,\n",
    "               'minmax_hag': 3.5,\n",
    "               'max_nz_flat': 0.85,\n",
    "               'min_width': 1.0,\n",
    "               'max_refl': -5.,\n",
    "               'max_ampl': 9.,\n",
    "               'min_nor': 1.5,\n",
    "               'nor_perc': 80}  # TODO\n",
    "\n",
    "# AHN classification\n",
    "AHN_OTHER = 1\n",
    "AHN_GROUND = 2\n",
    "AHN_BUILDING = 6\n",
    "AHN_WATER = 9\n",
    "AHN_ARTIFACT = 26\n",
    "\n",
    "# Our classification\n",
    "UNKNOWN = 0\n",
    "TREE = 1\n",
    "NOISE = 2\n",
    "OTHER = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d265f-474d-4191-bc98-290b2cc1ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create DTM reader\n",
    "ahn_reader = ahn_utils.NPZReader(ahn_dtm_folder, caching=False)\n",
    "\n",
    "# # Load tree locations\n",
    "# if Path(tree_ref_file).is_file():\n",
    "#     # We use XY Rijksdriehoek coordinates (epsg:28992), You can use epsg:4326 for wgs84\n",
    "#     tree_gdf = gpd.read_file(tree_ref_file, crs='epsg:28992')\n",
    "# else:\n",
    "#     print('Reference file with known tree locations is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8364d-c398-46dc-8b19-424f5d6e316c",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89643a0-b975-41f3-959b-cb2c10bae8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = list(pathlib.Path(input_dir).glob('ahn4*.laz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178387e1-b913-4df3-a076-ad8aa21a7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check existing output files (ignore this cell to re-run for all tiles)\n",
    "existing_files = list(pathlib.Path(output_dir).glob('trees*.laz'))\n",
    "existing_codes = {helpers.get_tilecode_from_filename(file.name)\n",
    "                  for file in existing_files}\n",
    "\n",
    "input_files = [file for file in input_files\n",
    "               if helpers.get_tilecode_from_filename(file.name) not in existing_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33303bc4-3c29-483a-a4dd-fbae6cc4390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(input_files, unit='file', smoothing=0)\n",
    "\n",
    "for file in pbar:\n",
    "    tilecode = helpers.get_tilecode_from_filename(file.name)\n",
    "    pbar.set_postfix_str(tilecode)\n",
    "\n",
    "    # Load LAS data\n",
    "    las = laspy.read(file)\n",
    "    points_xyz = np.vstack((las.x, las.y, las.z)).T\n",
    "\n",
    "    # # Get trees inside LAS bounding box\n",
    "    # if Path(tree_ref_file).is_file():\n",
    "    #     bbox = sg.box(las.header.min[0], las.header.min[1], las.header.max[0], las.header.max[1], ccw=True)\n",
    "    #     trees_in_bbox = tree_gdf[tree_gdf.within(bbox)]\n",
    "    #     tree_points = list(trees_in_bbox['geometry'].values)\n",
    "\n",
    "\n",
    "    ### Reduce the point cloud\n",
    "\n",
    "    # Use only AHN_OTHER class\n",
    "    mask = (las.classification == AHN_OTHER)\n",
    "\n",
    "    # Remove points close to ground\n",
    "    ground_z = ahn_reader.interpolate(tilecode,\n",
    "                                      points_xyz[mask])\n",
    "    height_mask = (points_xyz[mask, 2] - ground_z >= MIN_HAG) | np.isnan(ground_z)\n",
    "\n",
    "    # Get scalar fields of masked cloud\n",
    "    orig_idx = np.where(mask)[0][height_mask]\n",
    "    xyz = points_xyz[orig_idx]\n",
    "    refl = las.Reflectance[orig_idx]\n",
    "    ampl = las.Amplitude[orig_idx]\n",
    "    nor = las.number_of_returns[orig_idx]\n",
    "\n",
    "    # New scalar fields\n",
    "    hag = np.around(xyz[:,2] - ground_z[height_mask], decimals=2)\n",
    "    normals = np.around(helpers.calculate_normals(xyz), decimals=2)\n",
    "\n",
    "    ### Label the point cloud\n",
    "\n",
    "    # Init masks\n",
    "    tree_mask = np.ones(len(xyz), dtype=bool) \n",
    "    new_hag = np.copy(hag) # Because we index and manipulate this array in a for loop\n",
    "\n",
    "    ## Label \"tree\" clusters based on ground truth tree points\n",
    "    lcc = LabelConnectedComp(grid_size=tree_filter['grid_size'],\n",
    "                             min_component_size=tree_filter['min_component_size'])\n",
    "    point_components = lcc.get_components(xyz)\n",
    "\n",
    "    # Noise filter\n",
    "    tree_mask[point_components == -1] = False\n",
    "\n",
    "    cc_labels = np.unique(point_components)\n",
    "    cc_labels = set(cc_labels).difference((-1,))\n",
    "\n",
    "    # Iterate over the clusters\n",
    "    for cc in tqdm(cc_labels, smoothing=0, leave=False):\n",
    "        # select points that belong to the cluster\n",
    "        cc_mask = (point_components == cc)\n",
    "\n",
    "        # The height above ground values are unknown when a tree is partially above water. \n",
    "        # To \"standardize\" the HAG values per tree, we correct them based on the average HAG for each tree cluster.\n",
    "        # If a cluster has no valid HAG values, the NAP (z-coordinate) value is used instead.\n",
    "        cc_z = xyz[cc_mask][:, 2]\n",
    "        cc_hag = hag[cc_mask]\n",
    "        if np.isnan(cc_hag).all():\n",
    "            cc_offset = 0.\n",
    "        else:\n",
    "            cc_offset = np.nanmean(cc_hag) - np.mean(cc_z)\n",
    "        cc_hag = cc_z + cc_offset\n",
    "        hag[cc_mask] = cc_hag\n",
    "\n",
    "\n",
    "        ## Filters\n",
    "\n",
    "        # If most of the points point up, it's not a tree.\n",
    "        if np.abs(normals[:,2][cc_mask]).mean() > tree_filter['max_nz_flat']:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # TODO come up with something clever for x/y flatness\n",
    "        # Do a similar thing with the x normals\n",
    "        # elif normals[:,0][cc_mask].mean() < 0.03 and normals[:,0][cc_mask].mean() > -0.03:\n",
    "        #     tree_mask[cc_mask] = False\n",
    "\n",
    "        # If reflectance is too high, it's not a tree.\n",
    "        elif np.mean(refl[cc_mask]) > tree_filter['max_refl']:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # If amplitude is too high, it's not a tree.\n",
    "        elif np.mean(ampl[cc_mask]) > tree_filter['max_ampl']:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # If number_of_returns is too low, it's not a tree.\n",
    "        elif np.percentile(nor[cc_mask], tree_filter['nor_perc']) < tree_filter['min_nor']:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # Look at shape of cluster, e.g. minimum bounding rectangle + min_width check.\n",
    "        # min_dim, _ = helpers.get_wl_box(xyz[cc_mask])\n",
    "        elif helpers.get_wl_box(xyz[cc_mask])[0] < tree_filter['min_width']:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # If the object is smaller than MIN_HEIGHT or higher than MAX_HEIGHT, it's not a tree.\n",
    "        elif np.nanmax(cc_hag) < tree_filter['minmax_hag']:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "    ## Set labels\n",
    "    labels = np.ones((len(xyz),), dtype='uint16') * UNKNOWN\n",
    "    labels[tree_mask] = TREE\n",
    "\n",
    "\n",
    "    ### Save the point cloud\n",
    "\n",
    "    header = laspy.LasHeader(point_format=las.header.point_format,\n",
    "                             version=las.header.version)\n",
    "    header.offsets = las.header.offsets\n",
    "    header.scales = las.header.scales\n",
    "\n",
    "    new_las = laspy.LasData(header)\n",
    "\n",
    "    new_las.points = las.points[orig_idx]\n",
    "\n",
    "    new_las.add_extra_dim(laspy.ExtraBytesParams(name=\"label\", type=\"uint16\",\n",
    "                                                 description=\"Label\"))  \n",
    "    new_las.add_extra_dim(laspy.ExtraBytesParams(name=\"orig_idx\", type=\"uint32\",\n",
    "                                                 description=\"Original index\"))  \n",
    "    new_las.add_extra_dim(laspy.ExtraBytesParams(name=\"hag\", type=\"float\",\n",
    "                                                 description=\"Height above ground\"))\n",
    "    # new_las.add_extra_dim(laspy.ExtraBytesParams(name=\"normal_x\", type=\"float\",\n",
    "    #                                              description=\"normal_x\"))\n",
    "    # new_las.add_extra_dim(laspy.ExtraBytesParams(name=\"normal_y\", type=\"float\",\n",
    "    #                                              description=\"normal_y\"))    \n",
    "    # new_las.add_extra_dim(laspy.ExtraBytesParams(name=\"normal_z\", type=\"float\",\n",
    "    #                                              description=\"normal_z\"))\n",
    "\n",
    "    new_las.label = labels\n",
    "    new_las.orig_idx = orig_idx\n",
    "    new_las.hag = hag\n",
    "    # new_las.normal_x = normals[:,0]\n",
    "    # new_las.normal_y = normals[:,1]\n",
    "    # new_las.normal_z = normals[:,2]\n",
    "\n",
    "    new_las.write(output_dir / f'trees_{tilecode}.laz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba2e60-05be-4f27-bcf1-d07961e162b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
