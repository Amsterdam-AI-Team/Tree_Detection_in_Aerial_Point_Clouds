{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344c6f6a-6a65-4fd5-901f-ad233350078b",
   "metadata": {},
   "source": [
    "# Pre-processing and Filtering\n",
    "\n",
    "This notebook takes as input a folder with AHN point cloud tiles (assumed to be 1x1 km), and performs a number of pre-processing and filtering steps. The output is a reduced point cloud containing probable trees and other \"unknown\" elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ba0cd-6204-4b97-8739-fa01dd93bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path\n",
    "\n",
    "import numpy as np\n",
    "import laspy\n",
    "import pathlib\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from upcp.utils import ahn_utils\n",
    "from upcp.region_growing.label_connected_comp import LabelConnectedComp\n",
    "\n",
    "import gvl.helper_functions as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de515d-1ad2-48a9-afd7-7b6e09eb093e",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d5655-b6b9-4e74-bdee-27d8914c9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = pathlib.Path(\"../data\")\n",
    "OUTPUT_FOLDER = pathlib.Path(\"../data\")\n",
    "\n",
    "# Input: AHN subtiles created using notebook \"0. LAS Splitter.ipynb\"\n",
    "input_dir = DATA_FOLDER / \"ahn4\"\n",
    "output_dir = OUTPUT_FOLDER / \"ahn4_trees\"\n",
    "N = 4  # Number of digits in tilecode format\n",
    "\n",
    "# DTM corresponding to AHN subtiles, stored as .npz, created using notebook \"0. LAS Splitter.ipynb\"\n",
    "ahn_dtm_folder = DATA_FOLDER / \"ahn4\"\n",
    "\n",
    "MIN_HAG = 1.5  # Minimum height above ground (meters), used to cut off noise like cars, bushes\n",
    "\n",
    "# Tree filter settings, fine-tune these to your needs to balance FP / FN.\n",
    "tree_filter = {\n",
    "    \"grid_size\": 0.4,  # 0.5 grid size, input LCC, maximum distance\n",
    "    \"min_component_size\": 50,  # minimum component size, input LCC, minimum number of samples\n",
    "    \"minmax_hag\": 3.5,  # if its smaller than this height, it is not a tree\n",
    "    \"max_nz_flat\": 0.85,  # maximum amount of points that point up\n",
    "    \"min_nz_flat\": 0.5,  # minimum amount of points that point up\n",
    "    \"min_width\": 1.0,  # if width is smaller than this, it is not a tree\n",
    "    \"max_refl\": -5.0,  # maximum reflectance\n",
    "    \"max_ampl\": 9.0,  # maximum amplitude\n",
    "    \"min_nor\": 1.5,  # minimum number of returns\n",
    "    \"nor_perc\": 80,  # number of returns percentile (at which the min nor check is performed)\n",
    "}\n",
    "\n",
    "# AHN classification\n",
    "AHN_OTHER = 1\n",
    "AHN_GROUND = 2\n",
    "AHN_BUILDING = 6\n",
    "AHN_WATER = 9\n",
    "AHN_ARTIFACT = 26\n",
    "\n",
    "# Our classification\n",
    "UNKNOWN = 0\n",
    "TREE = 1\n",
    "NOISE = 2\n",
    "OTHER = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d265f-474d-4191-bc98-290b2cc1ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create DTM reader\n",
    "ahn_reader = ahn_utils.NPZReader(ahn_dtm_folder, caching=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8364d-c398-46dc-8b19-424f5d6e316c",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89643a0-b975-41f3-959b-cb2c10bae8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = list(input_dir.glob(\"ahn*.laz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178387e1-b913-4df3-a076-ad8aa21a7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check existing output files (ignore this cell to re-run for all tiles)\n",
    "existing_files = list(pathlib.Path(output_dir).glob(\"trees*.laz\"))\n",
    "existing_codes = {\n",
    "    utils.get_tilecode_from_filename(file.name, n_digits=N) for file in existing_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [\n",
    "    file\n",
    "    for file in input_files\n",
    "    if utils.get_tilecode_from_filename(file.name, n_digits=N) not in existing_codes\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2eb04-9808-45f9-843c-1da118b7d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(input_files, unit=\"file\", smoothing=0)\n",
    "\n",
    "for file in pbar:\n",
    "    tilecode = utils.get_tilecode_from_filename(file.name, n_digits=N)\n",
    "    pbar.set_postfix_str(tilecode)\n",
    "\n",
    "    # Load LAS data\n",
    "    las = laspy.read(file)\n",
    "    points_xyz = np.vstack((las.x, las.y, las.z)).T\n",
    "\n",
    "    ### Reduce the point cloud\n",
    "\n",
    "    # Use only AHN_OTHER class\n",
    "    mask = las.classification == AHN_OTHER\n",
    "\n",
    "    # Remove points close to ground\n",
    "    ground_z = ahn_reader.interpolate(tilecode, points_xyz[mask])\n",
    "    height_mask = (points_xyz[mask, 2] - ground_z >= MIN_HAG) | np.isnan(ground_z)\n",
    "\n",
    "    # Get scalar fields of masked cloud\n",
    "    orig_idx = np.where(mask)[0][height_mask]\n",
    "    if len(orig_idx) == 0:\n",
    "        continue\n",
    "\n",
    "    xyz = points_xyz[orig_idx]\n",
    "    refl = las.Reflectance[orig_idx]\n",
    "    ampl = las.Amplitude[orig_idx]\n",
    "    nor = las.number_of_returns[orig_idx]\n",
    "\n",
    "    # New scalar fields\n",
    "    hag = np.around(xyz[:, 2] - ground_z[height_mask], decimals=2)\n",
    "    normals = np.around(utils.calculate_normals(xyz), decimals=2)\n",
    "\n",
    "    ### Label the point cloud\n",
    "\n",
    "    # Init masks\n",
    "    tree_mask = np.ones(len(xyz), dtype=bool)\n",
    "    new_hag = np.copy(hag)  # Because we index and manipulate this array in a for loop\n",
    "\n",
    "    ## Cluster the point cloud data\n",
    "    lcc = LabelConnectedComp(\n",
    "        grid_size=tree_filter[\"grid_size\"],\n",
    "        min_component_size=tree_filter[\"min_component_size\"],\n",
    "    )\n",
    "    point_components = lcc.get_components(xyz)\n",
    "\n",
    "    # Noise filter\n",
    "    tree_mask[point_components == -1] = False\n",
    "\n",
    "    cc_labels = np.unique(point_components)\n",
    "    cc_labels = set(cc_labels).difference((-1,))\n",
    "\n",
    "    # Iterate over the clusters\n",
    "    for cc in tqdm(cc_labels, smoothing=0, leave=False):\n",
    "        # select points that belong to the cluster\n",
    "        cc_mask = np.where(point_components == cc)[0]\n",
    "\n",
    "        # The height above ground values are unknown when a tree is partially above water.\n",
    "        # To \"standardize\" the HAG values per tree, we correct them based on the average HAG\n",
    "        # for each tree cluster.\n",
    "        # If a cluster has no valid HAG values, the NAP (z-coordinate) value is used instead.\n",
    "        cc_z = xyz[cc_mask][:, 2]\n",
    "        cc_hag = hag[cc_mask]\n",
    "\n",
    "        if not np.isnan(cc_hag).all():\n",
    "            unknown = np.isnan(cc_hag)\n",
    "            if np.count_nonzero(unknown) > 0:\n",
    "                known_idx = np.where(~unknown)[0]\n",
    "                min_point = np.nanargmin(cc_z[known_idx])\n",
    "                if np.ndim(min_point) > 0:\n",
    "                    min_point = min_point[0]\n",
    "                cc_offset = cc_hag[known_idx[min_point]] - cc_z[known_idx[min_point]]\n",
    "                if np.isnan(cc_offset):\n",
    "                    print(\n",
    "                        f\"HAG: {cc_hag[known_idx[min_point]]}, NAP: {cc_z[known_idx[min_point]]}\"\n",
    "                    )\n",
    "                cc_hag[unknown] = cc_z[unknown] + cc_offset\n",
    "                new_hag[cc_mask] = cc_hag\n",
    "\n",
    "        ## Filters\n",
    "\n",
    "        # If most of the points point up, it's not a tree.\n",
    "        if np.abs(normals[:, 2][cc_mask]).mean() > tree_filter[\"max_nz_flat\"]:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        ## If too little of the points point up, it's not a tree.  # NEW\n",
    "        if np.abs(normals[:, 2][cc_mask]).mean() < tree_filter[\"min_nz_flat\"]:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # TODO come up with something clever for x/y flatness\n",
    "        # Do a similar thing with the x normals\n",
    "        # elif normals[:,0][cc_mask].mean() < 0.03 and normals[:,0][cc_mask].mean() > -0.03:\n",
    "        #     tree_mask[cc_mask] = False\n",
    "\n",
    "        # If reflectance is too high, it's not a tree.\n",
    "        elif np.mean(refl[cc_mask]) > tree_filter[\"max_refl\"]:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # If amplitude is too high, it's not a tree.\n",
    "        elif np.mean(ampl[cc_mask]) > tree_filter[\"max_ampl\"]:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # If number_of_returns is too low, it's not a tree.\n",
    "        elif (\n",
    "            np.percentile(nor[cc_mask], tree_filter[\"nor_perc\"])\n",
    "            < tree_filter[\"min_nor\"]\n",
    "        ):\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # Look at shape of cluster, e.g. minimum bounding rectangle + min_width check.\n",
    "        elif utils.get_wl_box(xyz[cc_mask])[0] < tree_filter[\"min_width\"]:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "        # If the object is smaller than MIN_HEIGHT or higher than MAX_HEIGHT, it's not a tree.\n",
    "        elif np.nanmax(cc_hag) < tree_filter[\"minmax_hag\"]:\n",
    "            tree_mask[cc_mask] = False\n",
    "\n",
    "    ## Set labels\n",
    "    labels = np.ones((len(xyz),), dtype=\"uint16\") * UNKNOWN\n",
    "    labels[tree_mask] = TREE\n",
    "\n",
    "    ### Save the point cloud\n",
    "\n",
    "    header = laspy.LasHeader(\n",
    "        point_format=las.header.point_format, version=las.header.version\n",
    "    )\n",
    "    header.offsets = las.header.offsets\n",
    "    header.scales = las.header.scales\n",
    "\n",
    "    new_las = laspy.LasData(header)\n",
    "\n",
    "    new_las.points = las.points[orig_idx]\n",
    "\n",
    "    new_las.add_extra_dim(\n",
    "        laspy.ExtraBytesParams(name=\"label\", type=\"uint16\", description=\"Label\")\n",
    "    )\n",
    "    new_las.add_extra_dim(\n",
    "        laspy.ExtraBytesParams(\n",
    "            name=\"orig_idx\", type=\"uint32\", description=\"Original index\"\n",
    "        )\n",
    "    )\n",
    "    new_las.add_extra_dim(\n",
    "        laspy.ExtraBytesParams(\n",
    "            name=\"hag\", type=\"float\", description=\"Height above ground\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    new_las.label = labels\n",
    "    new_las.orig_idx = orig_idx\n",
    "    new_las.hag = new_hag\n",
    "\n",
    "    new_las.write(output_dir / f\"trees_{tilecode}.laz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
